{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First will import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*As the page that we want to withdraw information has an Iframe, which means that we need to find URL that is requested the info we need. The original URL is https://congressoemfoco.uol.com.br/voce-conhece-seus-deputados-federais/, and inspecting it we find the source for the Iframe, this page requests an agent in order to allow access, thus the headers in the code.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://www.imagino.com.br/gerador/listagem.php\", headers={\"User-Agent\": \"XY\"})\n",
    "sep = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The info we want is in a separated URL, and is individual for the deputy and senator so we will create a variable containing a list of all the links*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = [link.get('href') for link in sep.select('a')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We want to have the resume info from each candidate, in a separeted .txt file and each file named after the candidate, to accomplish this we will make a for loop. Due to a broken link, we had to add an exception so the loop would not break*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in links:\n",
    "    try:\n",
    "        pg = requests.get(url)\n",
    "        soup = BeautifulSoup(pg.content, 'html.parser')\n",
    "        name = soup.find('div', class_ = 'nome').text\n",
    "        res = soup.find('div', class_ = 'resumo').text\n",
    "        with open(\"%s.txt\" % (name), \"a+\") as f:\n",
    "            print(res)\n",
    "            f.write(res)\n",
    "            \n",
    "    except AttributeError:\n",
    "        with open(\"%s.txt\" % (name), \"a+\") as f:\n",
    "            print(\"Resumo Não Encontrado\")\n",
    "            f.write(\"Resumo Não Encontrado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The result will appear in the folder of the code*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
